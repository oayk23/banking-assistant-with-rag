# ğŸ’³ Banking Assistant â€“ RAG-Powered AI for Smarter Customer Support

**Banking Assistant** is an intelligent, retrieval-augmented generation (RAG) system designed to streamline and enhance customer support experiences in the banking domain. Built with a blend of modern NLP techniques and LLM integration, this assistant delivers accurate, context-aware responses to user queries by retrieving the most relevant documentation snippets from a vectorized knowledge base.

---

## ğŸš€ Project Highlights

- ğŸ” **RAG (Retrieval-Augmented Generation):** Combines semantic search with generative AI to produce informed, real-time answers.
- ğŸ§  **FAISS Vector Store:** Fast similarity search over embeddings to fetch contextually relevant documents.
- ğŸ¤– **Transformers:** Utilizes HuggingFace models for both embedding generation and response generation.
- ğŸ“‚ **Intent Classification:** Routes user inputs to the right sub-knowledge base based on their detected intent.
- ğŸ”§ **Modular Pipeline:** Each step â€“ from preprocessing and indexing to querying and response generation â€“ is modularized for easy experimentation and extension.
- ğŸŒ **API-Ready:** Interact with the assistant through a simple RESTful interface.

---

## âš™ï¸ Setup Instructions

You can set up the project easily by running the platform-specific setup script.  

### On Linux / macOS:
```bash
bash setup.sh
```
### On Windows:
```bash
setup.bat
```
These scripts will install necessary dependencies and set up the environment for smooth execution.
---
## ğŸ§ª How It Works
1. Instruction Normalization: User prompts are cleaned and normalized for clarity.

2. Intent Classification: A lightweight classifier determines the intent category (e.g., card issues, account access, loan queries).

3. Vector Search with FAISS: Based on the intent, a corresponding FAISS index is queried for relevant documents.

4. Contextual Generation: The top-k relevant documents are passed as context to a transformer-based LLM, which generates the final response.

## âš ï¸ Limitations
- ğŸ’¾ Memory Usage: Embedding and querying large-scale document corpora may cause memory spikes. Batch size and model selection should be adjusted accordingly for limited environments.

- ğŸ§  Model Size Constraints: Low-parameter models may struggle with nuanced generation or instruction-following. Higher-performance results are achievable with larger models (e.g., Mistral, LLaMA, or GPT variants).

- ğŸ—ƒï¸ Static Corpus: The current system operates over a static indexed corpus. Real-time document updates require re-indexing.

- ğŸŒ No External API Integration Yet: This version doesn't fetch real-time banking data (e.g., account balances, transactions).

## ğŸ”Œ API Usage
The system is accessible via an API endpoint. Hereâ€™s a basic example of how to interact:
```
POST /chat
Content-Type: application/json

{
  "query": "My card got stuck in the ATM, what should I do?"
}
Response:
```
```
{
  "response": "I understand how frustrating it can be to have your card swallowed by an ATM. Here's what you can do..."
}
```
The API layer allows easy integration with chat interfaces, mobile apps, or internal support tools.

## ğŸŒŸ Future Directions
- Real-time document ingestion and indexing

- User feedback loop for response refinement

- Fine-tuned intent classifier

- Multi-language support

## ğŸ“ Folder Structure Overview
```
banking-assistant/
â”œâ”€â”€ setup.sh / setup.bat      # Setup scripts for dependencies
â”œâ”€â”€ banking_assistant/
â”‚   â”œâ”€â”€ embedder.py           # Embedding logic using transformers
â”‚   â”œâ”€â”€ correcter.py          # grammar and spelling correcter module
â”‚   â”œâ”€â”€ classifier/           # Intent classification module
|       â”œâ”€â”€ train.py
|       â”œâ”€â”€ inference.py      
â”‚   â”œâ”€â”€ llm.py                # LLM pipeline
â”‚   â”œâ”€â”€ full_pipeline.py      # Full Pipeline
â”œâ”€â”€ data_preparation/         # Data Preparation Package
â”‚   â”œâ”€â”€ correct_instructions.py # Instruct Correcter
â”œâ”€â”€ index_preparation/        # Index Preparation Package
â”‚   â”œâ”€â”€ index_preparation.py  # Prepares Vector Embeddings
â”œâ”€â”€ app.py                    # Restful api with FastAPI
â”œâ”€â”€ main.py                   # main.py file that prepares indexes,classifiers etc.
â”œâ”€â”€ inference.py              # inference file
```
## âœ¨ Final Notes
Banking Assistant demonstrates how retrieval-augmented LLM systems can be harnessed for domain-specific applications with precision and efficiency. Whether integrated into an enterprise solution or used as a research base, it showcases a clean architecture ready for real-world challenges.

Feel free to fork, extend, and contribute!

## ğŸ“¬ Contact
For issues, suggestions, or collaboration opportunities, feel free to open an issue or reach out.
